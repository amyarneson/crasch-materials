sch.k[j]
sum(data$sch.id.10 == "301770")
View(Tr.j)
Tr.j$psc[1] - Co.j$psc < caliper
which(Tr.j$psc[1] - Co.j$psc < caliper)
Co.i <- Co.j[which(Tr.j$psc[1] - Co.j$psc < caliper)]
Co.i <- Co.j[which(Tr.j$psc[1] - Co.j$psc < caliper),]
?mahalanobis
View(data)
mahal.cols <- 31:33 # this is arbitrary with the subset of variables, choose meaningful ones in full data set
k=1
Co.k <- data.frame(data[group == levels(group)[k] & data$mathpart10 == 0,c(2:7,mahal.cols)],
psc = psc.logit[group == levels(group)[k] & data$mathpart10 == 0])
sch.k <- unique(data$sch.id.10[group == levels(group)[k]])
j=1
Tr.j <- data.frame(data[data$sch.id.10 == sch.k[j] & data$mathpart10 == 1,c(2:7,mahal.cols)],
psc=psc.logit[data$sch.id.10 == sch.k[j] & data$mathpart10 == 1])
Co.j <- data.frame(data[data$sch.id.10 == sch.k[j] & data$mathpart10 == 0,c(2:7,mahal.cols)],
psc=psc.logit[data$sch.id.10 == sch.k[j] & data$mathpart10 == 0])
View(Tr.j)
View(Co.j)
ord <- sample(nrow(Tr.j))
ord
Co.i <- Co.j[which(Tr.j$psc[1] - Co.j$psc < caliper),]
Co.i
mahal.cov <- cov(data[,mahal.cols])
mahal.cov
?cov
mahal.cov <- cov(data[,mahal.cols],na.rm=TRUE)
mahal.cov <- cov(data[,mahal.cols],use="complete.obs")
mahal.cov
mahalanobis(x = Co.i[,7:(length(mahal.cols)-1)],
center = Tr.j[i,7:(length(mahal.cols)-1)],
cov = mahal.cov)
i = ord[1]
mahalanobis(x = Co.i[,7:(length(mahal.cols)-1)],
center = Tr.j[i,7:(length(mahal.cols)-1)],
cov = mahal.cov)
Co.i[,7:(length(mahal.cols)-1)]
Co.i[,7:(length(mahal.cols)+6)]
Tr.j[i,7:(length(mahal.cols)+6)]
mahalanobis(x = Co.i[,7:(length(mahal.cols)+6)],
center = Tr.j[i,7:(length(mahal.cols)+6)],
cov = mahal.cov)
class(Co.i[,7:(length(mahal.cols)+6)])
as.matrix(Co.i[,7:(length(mahal.cols)+6)])
class(Tr.j[i,7:(length(mahal.cols)+6)])
mahalanobis(x = as.matrix(Co.i[,7:(length(mahal.cols)+6)]),
center = as.vector(Tr.j[i,7:(length(mahal.cols)+6)]),
cov = mahal.cov)
mahalanobis(x = as.matrix(Co.i[,7:(length(mahal.cols)+6)]),
center = as.numeric(Tr.j[i,7:(length(mahal.cols)+6)]),
cov = mahal.cov)
?whichmin
?argmin
which.min(mahalanobis(x = as.matrix(Co.i[,7:(length(mahal.cols)+6)]),
center = as.numeric(Tr.j[i,7:(length(mahal.cols)+6)]),
cov = mahal.cov))
Co.pick <- which.min(mahalanobis(x = as.matrix(Co.i[,7:(length(mahal.cols)+6)]),
center = as.numeric(Tr.j[i,7:(length(mahal.cols)+6)]),
cov = mahal.cov))
Co.pick <- as.numeric(which.min(mahalanobis(x = as.matrix(Co.i[,7:(length(mahal.cols)+6)]),
center = as.numeric(Tr.j[i,7:(length(mahal.cols)+6)]),
cov = mahal.cov)))
rm(Co.pick)
Co.pick <- Co.i$std.id.10[(which.min(mahalanobis(x = as.matrix(Co.i[,7:(length(mahal.cols)+6)]),
center = as.numeric(Tr.j[i,7:(length(mahal.cols)+6)]),
cov = mahal.cov)))  ]
Co.pick
Co.pick <- as.factor(Co.i$std.id.10[(which.min(mahalanobis(x = as.matrix(Co.i[,7:(length(mahal.cols)+6)]),
center = as.numeric(Tr.j[i,7:(length(mahal.cols)+6)]),
cov = mahal.cov)))])
Co.pick
Co.i
data <- read.csv("C:/Users/Amy/OneDrive/DataSets/NAEA2010/NAEA2010g4.csv",stringsAsFactors=FALSE)
data[data=="."] = NA
data$sch.id.10 <- factor(data$sch.id.10)
data$math.ach10 <- as.numeric(data$math.ach10)
data$mathpart10 <- as.numeric(data$mathpart10)
data$female <- as.numeric(data$female)
data$preview10 <- as.numeric(data$preview10)
data$review10 <- as.numeric(data$review10)
data$prepare10 <- as.numeric(data$prepare10)
data$concentrate10 <- as.numeric(data$concentrate10)
data$question10 <- as.numeric(data$question10)
data$classpart10 <- as.numeric(data$classpart10)
data$adapt1.10 <- as.numeric(data$adapt1.10)
data$adapt2.10 <- as.numeric(data$adapt2.10)
data$atmosphere10 <- as.numeric(data$atmosphere10)
data$teacher1.10 <- as.numeric(data$teacher1.10)
data$teacher2.10 <- as.numeric(data$teacher2.10)
data$homework10 <- as.numeric(data$homework10)
data$tutoring10 <- as.numeric(data$tutoring10)
data$reading10 <- as.numeric(data$reading10)
data$EBS10 <- as.numeric(data$EBS10)
data$watchTV10 <- as.numeric(data$watchTV10)
data$comgame10 <- as.numeric(data$comgame10)
data$internet10 <- as.numeric(data$internet10)
data$friends10 <- as.numeric(data$friends10)
data$chore10 <- as.numeric(data$chore10)
# remove those missing on treatment assignment or outcome
dropped <- sum(is.na(data$mathpart10) | is.na(data$math.ach10))
data <- data[!is.na(data$mathpart10) & !is.na(data$math.ach10),]
std.caliper <- .25 # SD units
set.seed(764764) # for reproducability
group <- as.factor(data$region.10)
# determine which variables to include in Mahalanobis matching
mahal.cols <- 31:33 # this is arbitrary with the subset of variables, choose meaningful ones in full data set
mahal.cov <- cov(data[,mahal.cols],use="complete.obs")
pscore <- glm(mathpart10 ~ female + singlemom10 + singledad10 + orphan10 +
childhead10 + custodial10 + preview10 +
review10 + prepare10 + concentrate10 +
question10 + classpart10 + adapt1.10 +
adapt2.10 + atmosphere10 + teacher1.10 +
teacher2.10 + homework10 + tutoring10 +
reading10 + EBS10 + watchTV10 + comgame10 +
internet10 + friends10 + chore10,
family = "binomial",
data = data)
psc.logit <- pscore$linear.predictors
caliper <- std.caliper * sd(psc.logit)
Co.k <- data.frame(data[group == levels(group)[k] & data$mathpart10 == 0,c(2:7,mahal.cols)],
psc = psc.logit[group == levels(group)[k] & data$mathpart10 == 0])
sch.k <- unique(data$sch.id.10[group == levels(group)[k]])
Tr.j <- data.frame(data[data$sch.id.10 == sch.k[j] & data$mathpart10 == 1,c(2:7,mahal.cols)],
psc=psc.logit[data$sch.id.10 == sch.k[j] & data$mathpart10 == 1])
Co.j <- data.frame(data[data$sch.id.10 == sch.k[j] & data$mathpart10 == 0,c(2:7,mahal.cols)],
psc=psc.logit[data$sch.id.10 == sch.k[j] & data$mathpart10 == 0])
# proceed in random order
ord <- sample(nrow(Tr.j))
Co.i <- Co.j[which(Tr.j$psc[1] - Co.j$psc < caliper),]
Co.pick <- Co.i$std.id.10[(which.min(mahalanobis(x = as.matrix(Co.i[,7:(length(mahal.cols)+6)]),
center = as.numeric(Tr.j[i,7:(length(mahal.cols)+6)]),
cov = mahal.cov)))]
data$X.1 <- NULL
data$X <- 1:nrow(data)
View(data)
std.caliper <- .25 # SD units
set.seed(764764) # for reproducability
# 1. Identify site groupings
# use a factor variable
group <- as.factor(data$region.10)
# determine which variables to include in Mahalanobis matching
mahal.cols <- 31:33 # this is arbitrary with the subset of variables, choose meaningful ones in full data set
mahal.cov <- cov(data[,mahal.cols],use="complete.obs")
# 2. Propensity score estimation
# specify the pscore using glm (single-level) or glmer (multi-level)
pscore <- glm(mathpart10 ~ female + singlemom10 + singledad10 + orphan10 +
childhead10 + custodial10 + preview10 +
review10 + prepare10 + concentrate10 +
question10 + classpart10 + adapt1.10 +
adapt2.10 + atmosphere10 + teacher1.10 +
teacher2.10 + homework10 + tutoring10 +
reading10 + EBS10 + watchTV10 + comgame10 +
internet10 + friends10 + chore10,
family = "binomial",
data = data)
psc.logit <- pscore$linear.predictors
caliper <- std.caliper * sd(psc.logit)
Co.k <- data.frame(data[group == levels(group)[k] & data$mathpart10 == 0,c(2:7,mahal.cols)],
psc = psc.logit[group == levels(group)[k] & data$mathpart10 == 0])
sch.k <- unique(data$sch.id.10[group == levels(group)[k]])
mahal.cols <- 30:32 # this is arbitrary with the subset of variables, choose meaningful ones in full data set
Co.k <- data.frame(data[group == levels(group)[k] & data$mathpart10 == 0,c(1:6,mahal.cols)],
psc = psc.logit[group == levels(group)[k] & data$mathpart10 == 0])
sch.k <- unique(data$sch.id.10[group == levels(group)[k]])
Tr.j <- data.frame(data[data$sch.id.10 == sch.k[j] & data$mathpart10 == 1,c(1:6,mahal.cols)],
psc=psc.logit[data$sch.id.10 == sch.k[j] & data$mathpart10 == 1])
Co.j <- data.frame(data[data$sch.id.10 == sch.k[j] & data$mathpart10 == 0,c(1:6,mahal.cols)],
psc=psc.logit[data$sch.id.10 == sch.k[j] & data$mathpart10 == 0])
ord <- sample(nrow(Tr.j))
i = ord[1]
Co.i <- Co.j[which(Tr.j$psc[1] - Co.j$psc < caliper),]
Co.pick <- Co.i$std.id.10[(which.min(mahalanobis(x = as.matrix(Co.i[,7:(length(mahal.cols)+6)]),
center = as.numeric(Tr.j[i,7:(length(mahal.cols)+6)]),
cov = mahal.cov)))]
?vector
?sample
Tr.X <- vector(mode = "numeric", length = 0)
Tr.X = c(Tr.X,Tr.j$X[i]) # just save the row number - subset the full data later
Co = Co.i[Co.pick,]      # cannot just save the row number - adjusted controls will complicate that approach
Co
Co.pick <- Co.i[(which.min(mahalanobis(x = as.matrix(Co.i[,7:(length(mahal.cols)+6)]),
center = as.numeric(Tr.j[i,7:(length(mahal.cols)+6)]),
cov = mahal.cov))),]
Co.pick
data <- read.csv("C:/Users/Amy/OneDrive/DataSets/NAEA2010/NAEA2010g.csv",stringsAsFactors=FALSE)
View(data)
load("C:/Users/Amy/OneDrive/Berkeley/Papers/NAEA2009/pscore-spec/20150918_working_space.RData")
View(NAEA2010)
load("C:/Users/Amy/OneDrive/Berkeley/Papers/position2/empirical/prelim.RData")
library(lme4)
effects <- coef(pscore)
View(effects)
head(effects)
names(effects)
head(effects$sch.id.10)
class(effects$sch.id.10)
View(data)
?predict
test = predict(pscore)
head(test)
length(test)
test = predict(pscore,re.form = 0)
test = predict(pscore,re.form = ~0)
head(test)
test = predict(pscore,re.form = NA)
head(test)
nrow(effects$sch.id.10)
rm(test)
fixedpart <- predict(pscore, re.form = NA) # re.form = NA specifies only fixed effects to be used
coef(pscore)$sch.id.10[,1]
head(coef(pscore)$sch.id.10[,1])
head(names(coef(pscore)$sch.id.10[,1]))
head(names(coef(pscore)$sch.id.10))
head(row.names(coef(pscore)$sch.id.10))
REs <- matrix(c(coef(pscore)$sch.id.10[,1],
as.numeric(row.names(coef(pscore)$sch.id.10))),
ncol=2)
head(REs)
REs <- matrix(c(as.numeric(row.names(coef(pscore)$sch.id.10)),
coef(pscore)$sch.id.10[,1]),
ncol=2)
head(REs)
randEffs = list(ests = REs,
covariates = matrix(rep(1,467030),ncol = 1)
)
pScoreFix = fixedpart
treated = data$mathpart10
cluster = data$sch.id.10
group = data$region.10
Mahal = NULL
SDcaliper = 0.25
replace = FALSE
Mahal = NULL
if (!is.logical(treated)) { treated = as.logical(treated) }
if (is.factor(cluster)) { cluster = as.numeric(cluster) }
if (is.factor(group)) { group = as.numeric(group) }
if (is.null(SDcaliper)) {
caliper <- FALSE
} else {
caliper <- TRUE
cal <- SDcaliper * sd(pScore)
}
if (is.null(Mahal)) {
mahala <- FALSE
} else {
mahala <- TRUE
stopifnot(is.matrix(Mahal))
#check also that there are no incomplete cases and that there are same number of rows as the length of the other vectors
}
head(predict(pscore))
class(predict(pscore))
caliper <- sd(predict(pscore)) * .25
i <- j <- k <- 1
names(randEffs)
library(sirt)
?pcm.fit
?tam.fit
install.packages('multiMatch')
library(multiMatch)
install.packages('matchMulti')
sessionInfo()
install.packages('matchMulti')
library(matchMulti)
?matchMulti
?dchisq
library(matchMulti)
?matchMulti
data(catholic_schools)
View(catholic_schools)
catholic_schools$sectorf <- factor(catholic_schools$sector, label=c("Public", "Catholic"))
length(table(catholic_schools$school[catholic_schools$sector==1]))
#Number of Controls Schools
length(table(catholic_schools$school[catholic_schools$sector==0]))
nrow(catholic_schools)
library(ggplot2)
ggplot(catholic_schools, aes(x=sectorf, y=acad, fill=sectorf)) + geom_boxplot() +
guides(fill=FALSE) + xlab("") + ylab("Academic Track")
ggplot(catholic_schools, aes(x=sectorf, y=size, fill=sectorf)) + geom_boxplot() +
guides(fill=FALSE) + xlab("") + ylab("School Enrollment")
ggplot(catholic_schools, aes(x=sectorf, y=discrm, fill=sectorf)) + geom_boxplot() +
guides(fill=FALSE) + xlab("") + ylab("Disciplinary Climate")
ggplot(catholic_schools, aes(x=sectorf, y=female_mean, fill=sectorf)) + geom_boxplot() +
guides(fill=FALSE) + xlab("") + ylab("Percentage of Female Students")
library(mirt)
install.packages('mirt')
library(mirt)
?coef
methods(coef)
?mirt
library(dplyr)
summary(catholic_schools$female_mean)
summary(catholic_schools$female_mean[catholic_schools$sector==1])
summary(catholic_schools$female_mean[catholic_schools$sector==0])
catholic_schools <- catholic_schools %>% filter(female_mean>.30, female_mean<.75)
summary(catholic_schools$female_mean)
install.packages9'dplyr'
install.packages('dplyr')
library(dplyr)
summary(catholic_schools$female_mean)
summary(catholic_schools$female_mean[catholic_schools$sector==1])
summary(catholic_schools$female_mean[catholic_schools$sector==0])
catholic_schools <- catholic_schools %>% filter(female_mean>.30, female_mean<.75)
summary(catholic_schools$female_mean)
student.cov <- c('minority','female','ses')
school.cov <- c('minority_mean', 'female_mean', 'size', 'acad', 'discrm', 'ses_mean')
all.cov <- c('minority','female','ses','minority_mean', 'female_mean', 'size', 'acad', 'discrm', 'ses_mean')
#look at balance on students before matching
balanceTable(catholic_schools[c(all.cov,'sector')],  treatment = 'sector')
# Match Schools based on student covariates without pairing students
t_fexact <- system.time({
match.simple <- matchMulti(catholic_schools, treatment = 'sector',
school.id = 'school', match.students = FALSE,
student.vars = student.cov, verbose=TRUE)
})
install.packages('optmatch')
# Match Schools based on student covariates without pairing students
t_fexact <- system.time({
match.simple <- matchMulti(catholic_schools, treatment = 'sector',
school.id = 'school', match.students = FALSE,
student.vars = student.cov, verbose=TRUE)
})
nrow(match.simple$matched)
t_fexact[['elapsed']]/60
bal.tab
bal.tab <- balanceMulti(match.simple, student.cov = student.cov, school.cov = school.cov)
bal.tab
out <- cbind(bal.tab$schools[,3], bal.tab$schools[,6])
colnames(out) <- c("S.Diff Before", "S.Diff After")
round(out, 3)
# Now Match Students
t_fexact <- system.time({
match.out <- matchMulti(catholic_schools, treatment = 'sector',
school.id = 'school', match.students = TRUE,
student.vars = student.cov)
})
# time required for computation, in minutes
t_fexact[['elapsed']]/60
nrow(match.out$matched)
bal.tab.stu <- balanceMulti(match.out, student.cov = student.cov,
school.cov = school.cov)
out <- cbind(bal.tab.stu$schools[,3], bal.tab.stu$schools[,6])
colnames(out) <- c("S.Diff Before", "S.Diff After")
round(out, 3)
catholic_schools$acad_cut <- cut(catholic_schools$acad, 6)
catholic_schools$size_cut <- cut(catholic_schools$size, 6)
catholic_schools$discrm_cut <- cut(catholic_schools$discrm, 6)
catholic_schools$ses_cut <- cut(catholic_schools$ses_mean, 6)
# Now fine balance on school covariates
t_fexact <- system.time({
match.fb <- matchMulti(catholic_schools, treatment = 'sector',
school.id = 'school', match.students = TRUE, verbose=TRUE,
student.vars = student.cov,
school.fb = list(c('size_cut','acad_cut', 'discrm_cut', 'ses_cut')))
})
# time required for computation, in minutes
t_fexact[['elapsed']]/60
bal.tab.fb <- balanceMulti(match.fb, student.cov = student.cov, school.cov)
out2 <- cbind(bal.tab.fb$schools[,3], bal.tab.fb$schools[,6])
colnames(out2) <- c("S.Diff Before", "S.Diff After")
round(out2, 3)
table(paste(match.fb$matched$size_cut,
match.fb$matched$acad_cut, match.fb$matched$discrm_cut,
match.fb$matched$ses_cut, sep = '.'),
match.fb$matched$sector)
t_fexact <- system.time({
match.fb2 <- rematchSchools(match.fb, catholic_schools,
school.fb = list(c('acad_cut', 'discrm_cut'),
c('size_cut','acad_cut', 'discrm_cut', 'ses_cut')))
})
t_fexact[['elapsed']]/60
bal.tab3 <- balanceMulti(match.fb2, student.cov = student.cov, school.cov)
out3 <- cbind(bal.tab3$schools[,3], bal.tab3$schools[,6])
colnames(out3) <- c("S.Diff Before", "S.Diff After")
round(out3, 3)
?rematchSchools
match.fb4 <- rematchSchools(match.fb, catholic_schools,
school.fb = list(c('acad_cut', 'discrm_cut'),
c('size_cut','acad_cut', 'discrm_cut', 'ses_cut')),
keep.target = 10, tol = 0.1)
match.data <- as.data.frame(match.fb4$matched)
length(table(match.data$school[match.data$sector==1]))
rm(match.data)
bal.tab4 <- balanceMulti(match.fb4, student.cov = student.cov,
school.cov = c(school.cov))
out4 <- cbind(bal.tab4$schools[,3], bal.tab4$schools[,6])
colnames(out4) <- c("S.Diff Before", "S.Diff After")
round(out4, 3)
catholic_schools$acad_coarse <- cut(catholic_schools$acad, 2)
catholic_schools$size_coarse <- cut(catholic_schools$size, 2)
catholic_schools$discrm_coarse <- cut(catholic_schools$discrm, 2)
catholic_schools$ses_coarse <- cut(catholic_schools$ses_mean, 2)
catholic_schools$female_coarse <- cut(catholic_schools$female_mean, 2)
catholic_schools$minority_coarse <- cut(catholic_schools$minority_mean, 2)
catholic_schools$female_cut <- cut(catholic_schools$female_mean, 6)
catholic_schools$minority_cut <- cut(catholic_schools$minority_mean, 6)
# Now fine balance on school covariates
t_fexact <- system.time({
match.fb.alt <- matchMulti(catholic_schools, treatment = 'sector',
school.id = 'school', match.students = TRUE, verbose=TRUE,
student.vars = student.cov,
school.fb = list(c('size_coarse','acad_coarse', 'discrm_coarse', 'ses_coarse')))
})
# time required for computation, in minutes
t_fexact[['elapsed']]/60
bal.tab.fb.alt <- balanceMulti(match.fb.alt, student.cov = student.cov, school.cov)
out2.alt <- cbind(bal.tab.fb.alt$schools[,3], bal.tab.fb.alt$schools[,6])
colnames(out2.alt) <- c("S.Diff Before", "S.Diff After")
round(out2.alt, 3)
# Balance on interaction of nominals
table(paste(match.fb.alt$matched$size_coarse, match.fb.alt$matched$acad_coarse,
match.fb.alt$matched$discrm_coarse, match.fb.alt$matched$ses_coarse, sep = '.'),
match.fb.alt$matched$sector)
l1 <- c('minority_coarse')
l2 <- c(l1, 'size_coarse', 'ses_coarse', 'acad_coarse')
l3 <- c(l2, 'discrm_cut')
l4 <- c(l3, 'acad_cut','size_cut')
match.fb4.alt <- rematchSchools(match.fb.alt, catholic_schools,
school.fb = list( l1, l2, l3, l4),
keep.target = 10, tol = 0.1)
# How many schools now
length(table(match.fb4.alt$matched$school[match.fb4.alt$matched$sector==1]))
bal.tab4.alt <- balanceMulti(match.fb4.alt, student.cov = student.cov,
school.cov = c(school.cov))
out4.alt <- cbind(bal.tab4.alt$schools[,3], bal.tab4.alt$schools[,6])
colnames(out4.alt) <- c("S.Diff Before", "S.Diff After")
round(out4.alt, 3)
################  Balance Plots ################
################ Prep the Data ################
p.vals.um <- bal.tab4.alt$schools[,7]
N <- length(p.vals.um)
p.vals.pm <- bal.tab4.alt$schools[,8]
N.pm <- length(p.vals.pm)
std.um <- bal.tab4$schools[,3]
std.pm <- bal.tab4$schools[,6]
df <- data.frame(c(p.vals.um, p.vals.pm), c(std.um, std.pm),
c(rep(1,N), rep(2, N.pm)))
names(df) <- c("pval", "std", "cat")
df$std <- abs(df$std)
df$cat <- factor(df$cat,
levels = c(1,2),
labels = c("Unmatched", "Matched"))
################################################
# Plots
ggplot(df, aes(x=cat, y=pval, fill=cat)) + geom_boxplot() +
guides(fill=FALSE) + xlab("") + ylab("p-value") +
geom_hline(aes(yintercept=.05), colour="#990000", linetype="dashed")
ggplot(df, aes(x=cat, y=std, fill=cat)) + geom_boxplot() +
guides(fill=FALSE) + xlab("") + ylab("Standardized Difference") +
geom_hline(aes(yintercept=.10), colour="#990000", linetype="dashed")
match.data <- as.data.frame(match.fb4.alt$matched)
head(match.data)
require(nlme)
out <- lme(mathach ~ sector, random = ~ 1 | pair.id/school, data=match.data)
summary(out)
output.fb <- matchMultioutcome(match.fb4.alt, out.name = "mathach", schl_id_name = "school",  treat.name = "sector")
matchMultisens(match.fb4.alt, out.name = "mathach",
schl_id_name = "school",
treat.name = "sector")
matchMultisens(match.fb4.alt, out.name = "mathach",
schl_id_name = "school",
treat.name = "sector", Gamma=1.3)
output.fb <- matchMultioutcome(match.fb, out.name = "mathach", schl_id_name = "school",  treat.name = "sector")
matchMultisens(match.fb, out.name = "mathach",
schl_id_name = "school",
treat.name = "sector")
matchMultisens(match.fb, out.name = "mathach",
schl_id_name = "school",
treat.name = "sector", Gamma=2.17)
choose(7,2)
choose(9,2)
devtools::install_github("amyarneson/crasch")
library(crasch)
?crasch
installed.packages()
library(devtools)
install_github("amyarneson/crasch")
?item.scores
library(crasch)
?item.scores
?craschR
setwd("C:/Users/Amy/OneDrive/Development/crasch-materials/EDUC 274A/tutorial3-documents")
SUPcons = read.csv("SUPcons.csv", stringsAsFactors = FALSE)
SUPitem = read.csv("SUPitem.csv", stringsAsFactors = FALSE)
SUPscores = read.csv("SUPwide.csv", row.names = 1, stringsAsFactors = FALSE)
SUPvars = read.csv("SUPvars.csv", row.names = 1, stringsAsFactors = FALSE)
View(SUPcons)
SUPcons = read.csv("SUPcons.csv", stringsAsFactors = FALSE)
SUPitem = read.csv("SUPitem.csv", stringsAsFactors = FALSE)
SUPscores = read.csv("SUPwide.csv", row.names = 1, stringsAsFactors = FALSE)
SUPvars = read.csv("SUPvars.csv", row.names = 1, stringsAsFactors = FALSE)
View(SUPcons)
View(SUPitem)
View(SUPscores)
View(SUPvars)
?craschR
# The default analysis, without writing output to a file
SUPanalysis = craschR(scores = SUPscores, itemInfo = SUPitem,
consInfo = SUPcons, varsInfo = SUPvars, writeout = FALSE)
# The default person estimation method is EAP
# You can also obtain MLEs or WLEs
SUP_MLE = craschR(scores = SUPscores, itemInfo = SUPitem, consInfo = SUPcons,
varsInfo = SUPvars, persMethod = "MLE", writeout = FALSE)
SUP_WLE = craschR(scores = SUPscores, itemInfo = SUPitem, consInfo = SUPcons,
varsInfo = SUPvars, persMethod = "WLE", writeout = FALSE)
names(SUPanalysis'')
names(SUPanalysis)
SUPanalysis$persPars
cbind(SUPanalysis$persPars, SUP_MLE$persPars, SUP_WLE$persPars)
?item.scores
item.scores(SUPanalysis)
